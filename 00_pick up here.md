# Where you left off

2019-05-08 __ Give a quick read to multi-level models then read up on MCMC vocab like Markov chains

2019-05-07 I am now prioritizing completing the book and revisiting for depth. I will keep a list here of areas to revisit

2019-04-16 I am trying to create a brief overview of the justification for using deviance. I have had to do a lot of weeding, diving into density functions but I am getting there, and the weeding has been well worth the time. 
__ yet to fully grasp the meaning of "the log likelihood of the data" as used to calculate deviance.

2019-04-04 pick up on 6.3 to see how regularizing priors and information criteria address concerns about overfitting in out-of-sample deviance that were raised at the end of 6.2.

2019-04-03 pick up on understanding how *out-of-sample deviance* can provide a useful target for optimizing model performance. You are at 6.2.2 having just covered how models reflect our ignorance.

2019-04-02 I was trying to plot r-squared of weak and well fitting models in the hopes of better understanding r-squared. 

# Areas to revisit ####

__ How is the claim justified that you can know relative distance of 2 models from target when target is unknown? 

# For after this course ####
__ Perhaps a course to review modelr will refresh you on EDA for model fit as found in DataCamp. 

__ a review of probability might help a great deal. I would love to fall back on fluency in that as I read Stats books. Perhaps via Khan or [Datacamp](https://www.datacamp.com/courses/foundations-of-probability-in-r). I am having to take author's word for now on probability. 

__ a review of linear formulas on Khan and Datacamp would be very valuable for recognizing future formulas in your stats study. 